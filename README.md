# Audio-Based Environmental Awareness System for the Visually Impaired Using AI and Computer Vision

## Project Files and Descriptions

- **ffull.py** – Its the program with all the below codes integrated. 
- **fcb2.py** – A chatbot using LLaMA 3.2 locally with context awareness.  
- **fcbts.py** – An updated version of *fcb2.py* with audio output support.  
- **fcheck3.py** – Analyzes a given image using YOLO and the MiDaS monocular depth estimation model, then saves the data in *detss.json*.  
- **fhst.py** – A web-based chatbot application similar to *fcb2.py*.  
- **fmd3.py** – Uses the system's available camera to analyze the feed in real-time with YOLO and the MiDaS monocular depth estimation model, similar to *fcheck3.py*.  
- **1.jpg** – A reference image for testing with *fcheck3.py*.  
- **index.html** – The HTML interface for *fhst.py*.

And additionally we can use video streaming softwares from phone to PC like *Camo* to get RGB video stream directly from phone cameras and use it in above programs.
